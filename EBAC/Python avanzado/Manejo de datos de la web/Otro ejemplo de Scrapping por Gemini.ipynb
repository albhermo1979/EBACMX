{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec9a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def analizar_clarks():\n",
    "    # 1. Definimos la URL y las Cabeceras (Headers)\n",
    "    # Las 'headers' son importantes: engañan a la página para que crea \n",
    "    # que somos un navegador real y no un robot, evitando bloqueos.\n",
    "    url = \"https://www.liverpool.com.mx\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    print(f\"Conectando a {url}...\")\n",
    "\n",
    "    try:\n",
    "        # 2. Hacemos la petición (Request)\n",
    "        respuesta = requests.get(url, headers=headers)\n",
    "\n",
    "        # Verificamos si la conexión fue exitosa (Código 200)\n",
    "        if respuesta.status_code == 200:\n",
    "            print(\"¡Conexión exitosa! Analizando información...\\n\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "            # 3. Creamos el objeto Soup (Parseo)\n",
    "            soup = BeautifulSoup(respuesta.text, 'html.parser')\n",
    "\n",
    "            # --- EXTRACCIÓN 1: El título de la pestaña ---\n",
    "            titulo = soup.title.string.strip()\n",
    "            print(f\"TÍTULO DE LA PÁGINA:\\n{titulo}\")\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "            # --- EXTRACCIÓN 2: Obtener enlaces (Links) ---\n",
    "            # Buscamos todas las etiquetas 'a' (links) que tengan atributo 'href'\n",
    "            # Esto simula extraer el menú de navegación o categorías.\n",
    "            links = soup.find_all('a', href=True)\n",
    "\n",
    "            print(f\"ENLACES ENCONTRADOS (Mostrando los primeros 10):\")\n",
    "            contador = 0\n",
    "            for link in links:\n",
    "                texto_link = link.text.strip() # Limpiamos espacios vacíos\n",
    "                url_link = link['href']\n",
    "\n",
    "                # Solo imprimimos si el link tiene texto visible\n",
    "                if texto_link and contador < 10:\n",
    "                    print(f\"{contador + 1}. {texto_link} -> {url_link}\")\n",
    "                    contador += 1\n",
    "            \n",
    "            print(\"-\" * 40)\n",
    "            print(f\"Total de enlaces encontrados en la página: {len(links)}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Error al conectar. Código de estado: {respuesta.status_code}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error inesperado: {e}\")\n",
    "\n",
    "# Ejecutamos la función\n",
    "if __name__ == \"__main__\":\n",
    "    analizar_clarks()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
